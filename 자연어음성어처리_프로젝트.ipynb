{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1LILp5KvhHcw2QCOM_OpqsoKvm37sGSde",
      "authorship_tag": "ABX9TyMClx3H9SkI0OpRBoVUIQN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hongfruit/NLP_proj/blob/main/%EC%9E%90%EC%97%B0%EC%96%B4%EC%9D%8C%EC%84%B1%EC%96%B4%EC%B2%98%EB%A6%AC_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**나는 할 수 있다 아자아자~~!!**"
      ],
      "metadata": {
        "id": "pI7D0fqwjzja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI에게 한국인만 읽을 수 있는 리뷰 가르치기 전체 맥락\n",
        "\n",
        "**1. 토큰이 언어 모델에 들어가기 앞서 어순을 반영하기 위해 거치는 단계**\n",
        "* 토큰의 n차원 벡터와 어순을 반영하는 n차원 벡터(position Encoding)를 더해준다.\n",
        "\n",
        "    *why? 주어 you와 목적어 you가 다름을 표시하기 위함*\n",
        "\n",
        "\n",
        "* 토큰의 발음을 표현하는 n차원 벡터(Phonetic Encoding)도 같이 더함\n",
        "\n",
        "\n",
        "> 방법: 최대한 여러개의 영단어와 그 단어를 발음 기호로 전사한 쌍을 준비,\n",
        "        각 발음 기호의 음운자질(Phonetic feature) 준비.\n",
        "        **어쨋든 발음을 표현하는 벡터를 만든다. (나중에 자세히 설명)**\n",
        "\n",
        "\n",
        "-----\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-BmVRAADosoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**2.   잘 됐나 확인하기 위해 사전학습된 한국어-영어번역 모델을 사용해 파인튜닝 진행**\n",
        "\n",
        "\n",
        "```\n",
        "# Helsinki-NLP/opus-mt-ko-en\n",
        "```\n",
        "* 학습데이터?\n",
        "\n",
        "> 한영번역데이터 중 구어체에 노이즈 추가해 활용\n",
        "\n",
        "* 노이즈 추가?\n",
        "> 랜덤하게 k개의 어절을 고르고, 그 어절의 초성이 평음이면 랜덤하게 거센 소리 또는 된소리로 변형\n",
        "-----------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "yNAmFnZexVgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. 동일한 학습데이터를 가지고 기존 모델과 Phonetic Encoding을 추가한 모델의 학습 후 성능 비교**"
      ],
      "metadata": {
        "id": "zUL072bVxsma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "Nq3YjWEuOVlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "c3JVxJHoP-vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Sf_HMrntE1jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "id": "vCCBZCL2j3-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/crlotwhite/KoG2P_fork.git"
      ],
      "metadata": {
        "id": "rrQfattPE2Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kog2p\n",
        "\n",
        "kog2p.runKoG2P('모듈에 발음 특징 벡터를 생성하는 관련 함수 또는 클래스가 있다는 것을 나타냅니다.')"
      ],
      "metadata": {
        "id": "UwV6NTT59ZxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yeounyi/PhoneticTranslation.git"
      ],
      "metadata": {
        "id": "pV9LPVKQJep6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/korean-phonetic-vectors"
      ],
      "metadata": {
        "id": "RfjYQYDwirow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "metadata": {
        "id": "28L37sT_iquY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hgtk"
      ],
      "metadata": {
        "id": "_DKWg-_fkmbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Korean Phonetic Vectors"
      ],
      "metadata": {
        "id": "QFor4xy0nN7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from itertools import product\n",
        "from collections import Counter\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from KoG2P.g2p import runKoG2P\n",
        "from generate_phonetic_feature_vectors import *"
      ],
      "metadata": {
        "id": "giU9Xt9emw43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runKoG2P('박물관', 'KoG2P/rulebook.txt')"
      ],
      "metadata": {
        "id": "4sZKKNR3mxjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/ipa_feats.csv')\n",
        "df.features = df.features.apply(lambda x: tuple(x.split()))\n",
        "phone_feature_map = dict(df.values)\n",
        "phone_feature_map['^'] = tuple(['bgn'])\n",
        "phone_feature_map['$'] = tuple(['end'])\n",
        "phone_feature_map"
      ],
      "metadata": {
        "id": "Twh-WXdnm0KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('feat2vec.pickle', 'rb') as fp:\n",
        "    feat2vec = pickle.load(fp)"
      ],
      "metadata": {
        "id": "wfS0pn_Bm4LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word2phonvec(word):\n",
        "    \"\"\"Takes a korean word and returns a phonetic vector of it\n",
        "    \"\"\"\n",
        "    phones = runKoG2P(re.sub('[^가-힣]','', word), 'KoG2P/rulebook.txt')\n",
        "    features = Counter(feature_bigrams(phones.split(), phone_feature_map))\n",
        "    word_phonvec = np.zeros(512)\n",
        "    count = 0\n",
        "    for feature in features:\n",
        "        word_phonvec += feat2vec[feature] * features[feature]\n",
        "        count += features[feature]\n",
        "\n",
        "    word_phonvec = word_phonvec / count if count > 0 else word_phonvec\n",
        "\n",
        "    # 마지막에 음절 수 곱해주기\n",
        "    return word_phonvec * len(word)"
      ],
      "metadata": {
        "id": "9kVnAJ8qm5ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0NSBf4Sdm6g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PhoneticTranslation"
      ],
      "metadata": {
        "id": "ZMfK8JpBm65t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from MarianMTPhoneticModel import MarianMTPhoneticModel\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import torch\n",
        "from KoG2P.g2p import runKoG2P\n",
        "import hgtk\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n"
      ],
      "metadata": {
        "id": "YKBlle2oizE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")\n",
        "model = MarianMTPhoneticModel.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")"
      ],
      "metadata": {
        "id": "Dzuj6-cTi2MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ko_vocab_dict = {}\n",
        "for vocab in tqdm(tokenizer.encoder):\n",
        "    if re.findall('[^가-힣_]', vocab) or vocab == '_':\n",
        "        continue\n",
        "    ko_vocab_dict[vocab] = tokenizer.encoder[vocab]\n",
        "\n",
        "len(ko_vocab_dict) # 31307\n",
        "\n",
        "list(ko_vocab_dict.keys())[:10] # ['_들', '_이', '_을', '_의', '_은', '_에', '_가', '_는', '_를', '_그']\n",
        "\n",
        "vocab2phonvec = {}\n",
        "for vocab in tqdm(ko_vocab_dict):\n",
        "    vocab2phonvec[ko_vocab_dict[vocab]] = word2phonvec(vocab)\n",
        "\n",
        "with open('vocab2phonvec.pickle', 'wb') as fp:\n",
        "    pickle.dump(vocab2phonvec, fp)\n"
      ],
      "metadata": {
        "id": "dn9zj3mdkOm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('feat2vec.pickle', 'rb') as fp:\n",
        "    feat2vec = pickle.load(fp)\n",
        "\n",
        "with open ('vocab2phonvec.pickle', 'rb') as fp:\n",
        "    vocab2phonvec = pickle.load(fp)\n",
        "\n",
        "ipadf = pd.read_csv('data/ipa_feats.csv')\n",
        "ipadf.features = ipadf.features.apply(lambda x: tuple(x.split()))\n",
        "phone_feature_map = dict(ipadf.values)\n",
        "phone_feature_map['^'] = tuple(['bgn'])\n",
        "phone_feature_map['$'] = tuple(['end'])\n"
      ],
      "metadata": {
        "id": "cfz2ZYDDkSIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_phonetic_embedding(input_ids, sent):\n",
        "    embed_phonetic = []\n",
        "    if tokenizer.unk_token_id not in input_ids:\n",
        "        for token_id in input_ids:\n",
        "            if int(token_id) not in vocab2phonvec:\n",
        "                embed_phonetic.append(torch.zeros(512))\n",
        "            else:\n",
        "                embed_phonetic.append(torch.from_numpy(vocab2phonvec[int(token_id)]))\n",
        "    else:\n",
        "        tokenized_sent = tokenizer.tokenize(sent)\n",
        "        for token_id, token in zip(input_ids, tokenized_sent + ['<pad>'] * (len(input_ids) - len(tokenized_sent))):\n",
        "            if token_id == tokenizer.unk_token_id:\n",
        "                embed_phonetic.append(torch.from_numpy(word2phonvec(token)))\n",
        "            elif int(token_id) in vocab2phonvec:\n",
        "                embed_phonetic.append(torch.from_numpy(vocab2phonvec[int(token_id)]))\n",
        "            else:\n",
        "                embed_phonetic.append(torch.zeros(512))\n",
        "\n",
        "    return torch.stack(embed_phonetic).float()"
      ],
      "metadata": {
        "id": "RN6G-0JXnxZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phon_dict = {'ㄱ':['ㄲ','ㅋ'], 'ㄷ':['ㄸ','ㅌ'], 'ㅂ':['ㅃ','ㅍ'], 'ㅅ':['ㅆ'], 'ㅈ':['ㅉ','ㅊ']}\n",
        "\n",
        "def add_noise(eumjeol):\n",
        "    result = []\n",
        "    for i,phoneme in enumerate(hgtk.letter.decompose(eumjeol)):\n",
        "        # 종성은 변하지 않음\n",
        "        if i == 2 or phoneme not in phon_dict:\n",
        "            result.append(phoneme)\n",
        "        else:\n",
        "            result.append(random.choice(phon_dict[phoneme]))\n",
        "\n",
        "    if len(result) == 2:\n",
        "        return hgtk.letter.compose(result[0], result[1])\n",
        "    else:\n",
        "        try:\n",
        "            return hgtk.letter.compose(result[0], result[1], result[2])\n",
        "        except:\n",
        "            print(eumjeol, result)\n",
        "            return eumjeol"
      ],
      "metadata": {
        "id": "NZLyowpVn_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_noise_data(sent):\n",
        "    random_eojeols = random.choices(sent.split(), k=2)\n",
        "    for random_eojeol in random_eojeols:\n",
        "        if hgtk.checker.is_hangul(random_eojeol):\n",
        "            noised_eojeol = ''.join([add_noise(eumjeol) for eumjeol in random_eojeol])\n",
        "            sent = sent.replace(random_eojeol, noised_eojeol)\n",
        "    return sent"
      ],
      "metadata": {
        "id": "hn4ySLnGoBad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ko_sents=None, en_sents=None, tokenizer=None, label_yn=True):\n",
        "        self.label_yn = label_yn\n",
        "        inputs = tokenizer(ko_sents, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        self.input_ids = []\n",
        "        self.embed_phonetic = []\n",
        "        for input_id, sent in zip(inputs['input_ids'], ko_sents):\n",
        "            input_id = input_id.clone().detach()\n",
        "            emb_pho = get_phonetic_embedding(input_id, sent)\n",
        "            self.input_ids.append(input_id)\n",
        "            self.embed_phonetic.append(emb_pho)\n",
        "            assert len(input_id) == len(emb_pho)\n",
        "        self.attention_mask = [i.clone().detach() for i in inputs['attention_mask']]\n",
        "\n",
        "        if self.label_yn:\n",
        "            labels = tokenizer(en_sents, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "            self.labels = [i.clone().detach() for i in labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label_yn:\n",
        "            return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_mask[idx], \\\n",
        "                    'embed_phonetic': self.embed_phonetic[idx], 'labels': self.labels[idx]}\n",
        "        return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_mask[idx], \\\n",
        "                    'embed_phonetic': self.embed_phonetic[idx]}"
      ],
      "metadata": {
        "id": "XrKRbx46oDTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('mt-data.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "ynohVoscez72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "3js1D_d22Ifj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['noised_ko'] = df['원문'].apply(lambda x: build_noise_data(x))\n",
        "df['en']=df['번역문']\n",
        "\n",
        "msk = np.random.rand(len(df)) < 0.8\n",
        "\n",
        "train_df = df[msk]\n",
        "eval_df = df[~msk]\n",
        "\n",
        "train_df.to_csv('train.csv', index=False, encoding='utf-8')\n",
        "eval_df.to_csv('eval.csv', index=False, encoding='utf-8')\n",
        "\n",
        "train_data = CustomDataset(train_df.noised_ko.tolist(), train_df.en.tolist(), tokenizer)\n",
        "eval_data = CustomDataset(eval_df.noised_ko.tolist(), eval_df.en.tolist(), tokenizer)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# freeze original Bart Encoder, Decoder except the last layer\n",
        "# for param in model.model.encoder.layers[:-2].parameters():\n",
        "#     param.requires_grad = False\n",
        "# for param in model.model.decoder.layers[:-1].parameters():\n",
        "#    param.requires_grad = False\n",
        "\n",
        "\n",
        "# +\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    'PhoneticTranslation-noise2-epoch15-ckpt',\n",
        "    # load_best_model_at_end = True,\n",
        "    num_train_epochs=15,  # total # of training epochs\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
        "    # weight_decay=0.01,  # strength of weight decay\n",
        "    # eval_accumulation_steps=1,\n",
        "    save_steps = 999999999999999 # checkpoint 중간에 저장하지 말라고\n",
        ")\n",
        "# -\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,  # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,  # training arguments, defined above\n",
        "    train_dataset=train_data,  # training dataset\n",
        "    eval_dataset=eval_data,\n",
        "    # compute_metrics= compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.evaluate()\n",
        "\n",
        "model.save_pretrained('./PhoneticTranslationModel-noise2-epoch15')\n"
      ],
      "metadata": {
        "id": "qFU9St2ZkuV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inference_batch(ko_sents):\n",
        "        inputs = tokenizer(ko_sents, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        input_ids = []\n",
        "        embed_phonetic = []\n",
        "        for input_id, sent in zip(inputs['input_ids'], ko_sents):\n",
        "            input_ids.append(input_id.clone().detach())\n",
        "            embed_phonetic.append(get_phonetic_embedding(input_id, sent))\n",
        "        attention_mask = [i.clone().detach() for i in inputs['attention_mask']]\n",
        "\n",
        "        input_ids = torch.stack(input_ids)\n",
        "        attention_mask = torch.stack(attention_mask)\n",
        "        embed_phonetic = torch.stack(embed_phonetic).float()\n",
        "\n",
        "        return {'input_ids':input_ids, 'attention_mask':attention_mask, 'embed_phonetic':embed_phonetic}\n",
        "\n",
        "\n",
        "sample_texts = ['박물관이 어디 있나요?', \"빡물관이 어디 있나요?\", \"빡물콴이 어디 있나요?\", \"완쩐 뼐루에요\"]\n",
        "batch = get_inference_batch(sample_texts)\n",
        "generated_ids = model.generate(**batch)\n",
        "translated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "translated_texts\n",
        "\n",
        "for sample, result in zip(sample_texts, translated_texts):\n",
        "    print(f'{sample} --> {result}')\n"
      ],
      "metadata": {
        "id": "yGkQtOSToGxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "95LvM22Apj_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv korean-phonetic-vectors/ drive/MyDrive/"
      ],
      "metadata": {
        "id": "cNXabtD0pkm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yUCcFOtLpoUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}