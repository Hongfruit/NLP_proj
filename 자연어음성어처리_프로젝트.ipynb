{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1LILp5KvhHcw2QCOM_OpqsoKvm37sGSde",
      "authorship_tag": "ABX9TyMClx3H9SkI0OpRBoVUIQN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hongfruit/NLP_proj/blob/main/%EC%9E%90%EC%97%B0%EC%96%B4%EC%9D%8C%EC%84%B1%EC%96%B4%EC%B2%98%EB%A6%AC_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ÎÇòÎäî Ìï† Ïàò ÏûàÎã§ ÏïÑÏûêÏïÑÏûê~~!!**"
      ],
      "metadata": {
        "id": "pI7D0fqwjzja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AIÏóêÍ≤å ÌïúÍµ≠Ïù∏Îßå ÏùΩÏùÑ Ïàò ÏûàÎäî Î¶¨Î∑∞ Í∞ÄÎ•¥ÏπòÍ∏∞ Ï†ÑÏ≤¥ Îß•ÎùΩ\n",
        "\n",
        "**1. ÌÜ†ÌÅ∞Ïù¥ Ïñ∏Ïñ¥ Î™®Îç∏Ïóê Îì§Ïñ¥Í∞ÄÍ∏∞ ÏïûÏÑú Ïñ¥ÏàúÏùÑ Î∞òÏòÅÌïòÍ∏∞ ÏúÑÌï¥ Í±∞ÏπòÎäî Îã®Í≥Ñ**\n",
        "* ÌÜ†ÌÅ∞Ïùò nÏ∞®Ïõê Î≤°ÌÑ∞ÏôÄ Ïñ¥ÏàúÏùÑ Î∞òÏòÅÌïòÎäî nÏ∞®Ïõê Î≤°ÌÑ∞(position Encoding)Î•º ÎçîÌï¥Ï§ÄÎã§.\n",
        "\n",
        "    *why? Ï£ºÏñ¥ youÏôÄ Î™©Ï†ÅÏñ¥ youÍ∞Ä Îã§Î¶ÑÏùÑ ÌëúÏãúÌïòÍ∏∞ ÏúÑÌï®*\n",
        "\n",
        "\n",
        "* ÌÜ†ÌÅ∞Ïùò Î∞úÏùåÏùÑ ÌëúÌòÑÌïòÎäî nÏ∞®Ïõê Î≤°ÌÑ∞(Phonetic Encoding)ÎèÑ Í∞ôÏù¥ ÎçîÌï®\n",
        "\n",
        "\n",
        "> Î∞©Î≤ï: ÏµúÎåÄÌïú Ïó¨Îü¨Í∞úÏùò ÏòÅÎã®Ïñ¥ÏôÄ Í∑∏ Îã®Ïñ¥Î•º Î∞úÏùå Í∏∞Ìò∏Î°ú Ï†ÑÏÇ¨Ìïú ÏåçÏùÑ Ï§ÄÎπÑ,\n",
        "        Í∞Å Î∞úÏùå Í∏∞Ìò∏Ïùò ÏùåÏö¥ÏûêÏßà(Phonetic feature) Ï§ÄÎπÑ.\n",
        "        **Ïñ¥Ï®ãÎì† Î∞úÏùåÏùÑ ÌëúÌòÑÌïòÎäî Î≤°ÌÑ∞Î•º ÎßåÎì†Îã§. (ÎÇòÏ§ëÏóê ÏûêÏÑ∏Ìûà ÏÑ§Î™Ö)**\n",
        "\n",
        "\n",
        "-----\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-BmVRAADosoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**2.   Ïûò ÎêêÎÇò ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌï¥ ÏÇ¨Ï†ÑÌïôÏäµÎêú ÌïúÍµ≠Ïñ¥-ÏòÅÏñ¥Î≤àÏó≠ Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìï¥ ÌååÏù∏ÌäúÎãù ÏßÑÌñâ**\n",
        "\n",
        "\n",
        "```\n",
        "# Helsinki-NLP/opus-mt-ko-en\n",
        "```\n",
        "* ÌïôÏäµÎç∞Ïù¥ÌÑ∞?\n",
        "\n",
        "> ÌïúÏòÅÎ≤àÏó≠Îç∞Ïù¥ÌÑ∞ Ï§ë Íµ¨Ïñ¥Ï≤¥Ïóê ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞ÄÌï¥ ÌôúÏö©\n",
        "\n",
        "* ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä?\n",
        "> ÎûúÎç§ÌïòÍ≤å kÍ∞úÏùò Ïñ¥Ï†àÏùÑ Í≥†Î•¥Í≥†, Í∑∏ Ïñ¥Ï†àÏùò Ï¥àÏÑ±Ïù¥ ÌèâÏùåÏù¥Î©¥ ÎûúÎç§ÌïòÍ≤å Í±∞ÏÑº ÏÜåÎ¶¨ ÎòêÎäî ÎêúÏÜåÎ¶¨Î°ú Î≥ÄÌòï\n",
        "-----------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "yNAmFnZexVgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. ÎèôÏùºÌïú ÌïôÏäµÎç∞Ïù¥ÌÑ∞Î•º Í∞ÄÏßÄÍ≥† Í∏∞Ï°¥ Î™®Îç∏Í≥º Phonetic EncodingÏùÑ Ï∂îÍ∞ÄÌïú Î™®Îç∏Ïùò ÌïôÏäµ ÌõÑ ÏÑ±Îä• ÎπÑÍµê**"
      ],
      "metadata": {
        "id": "zUL072bVxsma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "Nq3YjWEuOVlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "c3JVxJHoP-vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Sf_HMrntE1jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "id": "vCCBZCL2j3-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/crlotwhite/KoG2P_fork.git"
      ],
      "metadata": {
        "id": "rrQfattPE2Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kog2p\n",
        "\n",
        "kog2p.runKoG2P('Î™®ÎìàÏóê Î∞úÏùå ÌäπÏßï Î≤°ÌÑ∞Î•º ÏÉùÏÑ±ÌïòÎäî Í¥ÄÎ†® Ìï®Ïàò ÎòêÎäî ÌÅ¥ÎûòÏä§Í∞Ä ÏûàÎã§Îäî Í≤ÉÏùÑ ÎÇòÌÉÄÎÉÖÎãàÎã§.')"
      ],
      "metadata": {
        "id": "UwV6NTT59ZxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yeounyi/PhoneticTranslation.git"
      ],
      "metadata": {
        "id": "pV9LPVKQJep6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/korean-phonetic-vectors"
      ],
      "metadata": {
        "id": "RfjYQYDwirow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "metadata": {
        "id": "28L37sT_iquY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hgtk"
      ],
      "metadata": {
        "id": "_DKWg-_fkmbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Korean Phonetic Vectors"
      ],
      "metadata": {
        "id": "QFor4xy0nN7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from itertools import product\n",
        "from collections import Counter\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from KoG2P.g2p import runKoG2P\n",
        "from generate_phonetic_feature_vectors import *"
      ],
      "metadata": {
        "id": "giU9Xt9emw43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runKoG2P('Î∞ïÎ¨ºÍ¥Ä', 'KoG2P/rulebook.txt')"
      ],
      "metadata": {
        "id": "4sZKKNR3mxjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/ipa_feats.csv')\n",
        "df.features = df.features.apply(lambda x: tuple(x.split()))\n",
        "phone_feature_map = dict(df.values)\n",
        "phone_feature_map['^'] = tuple(['bgn'])\n",
        "phone_feature_map['$'] = tuple(['end'])\n",
        "phone_feature_map"
      ],
      "metadata": {
        "id": "Twh-WXdnm0KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('feat2vec.pickle', 'rb') as fp:\n",
        "    feat2vec = pickle.load(fp)"
      ],
      "metadata": {
        "id": "wfS0pn_Bm4LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word2phonvec(word):\n",
        "    \"\"\"Takes a korean word and returns a phonetic vector of it\n",
        "    \"\"\"\n",
        "    phones = runKoG2P(re.sub('[^Í∞Ä-Ìû£]','', word), 'KoG2P/rulebook.txt')\n",
        "    features = Counter(feature_bigrams(phones.split(), phone_feature_map))\n",
        "    word_phonvec = np.zeros(512)\n",
        "    count = 0\n",
        "    for feature in features:\n",
        "        word_phonvec += feat2vec[feature] * features[feature]\n",
        "        count += features[feature]\n",
        "\n",
        "    word_phonvec = word_phonvec / count if count > 0 else word_phonvec\n",
        "\n",
        "    # ÎßàÏßÄÎßâÏóê ÏùåÏ†à Ïàò Í≥±Ìï¥Ï£ºÍ∏∞\n",
        "    return word_phonvec * len(word)"
      ],
      "metadata": {
        "id": "9kVnAJ8qm5ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0NSBf4Sdm6g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PhoneticTranslation"
      ],
      "metadata": {
        "id": "ZMfK8JpBm65t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from MarianMTPhoneticModel import MarianMTPhoneticModel\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import torch\n",
        "from KoG2P.g2p import runKoG2P\n",
        "import hgtk\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n"
      ],
      "metadata": {
        "id": "YKBlle2oizE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")\n",
        "model = MarianMTPhoneticModel.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")"
      ],
      "metadata": {
        "id": "Dzuj6-cTi2MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ko_vocab_dict = {}\n",
        "for vocab in tqdm(tokenizer.encoder):\n",
        "    if re.findall('[^Í∞Ä-Ìû£_]', vocab) or vocab == '_':\n",
        "        continue\n",
        "    ko_vocab_dict[vocab] = tokenizer.encoder[vocab]\n",
        "\n",
        "len(ko_vocab_dict) # 31307\n",
        "\n",
        "list(ko_vocab_dict.keys())[:10] # ['_Îì§', '_Ïù¥', '_ÏùÑ', '_Ïùò', '_ÏùÄ', '_Ïóê', '_Í∞Ä', '_Îäî', '_Î•º', '_Í∑∏']\n",
        "\n",
        "vocab2phonvec = {}\n",
        "for vocab in tqdm(ko_vocab_dict):\n",
        "    vocab2phonvec[ko_vocab_dict[vocab]] = word2phonvec(vocab)\n",
        "\n",
        "with open('vocab2phonvec.pickle', 'wb') as fp:\n",
        "    pickle.dump(vocab2phonvec, fp)\n"
      ],
      "metadata": {
        "id": "dn9zj3mdkOm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('feat2vec.pickle', 'rb') as fp:\n",
        "    feat2vec = pickle.load(fp)\n",
        "\n",
        "with open ('vocab2phonvec.pickle', 'rb') as fp:\n",
        "    vocab2phonvec = pickle.load(fp)\n",
        "\n",
        "ipadf = pd.read_csv('data/ipa_feats.csv')\n",
        "ipadf.features = ipadf.features.apply(lambda x: tuple(x.split()))\n",
        "phone_feature_map = dict(ipadf.values)\n",
        "phone_feature_map['^'] = tuple(['bgn'])\n",
        "phone_feature_map['$'] = tuple(['end'])\n"
      ],
      "metadata": {
        "id": "cfz2ZYDDkSIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_phonetic_embedding(input_ids, sent):\n",
        "    embed_phonetic = []\n",
        "    if tokenizer.unk_token_id not in input_ids:\n",
        "        for token_id in input_ids:\n",
        "            if int(token_id) not in vocab2phonvec:\n",
        "                embed_phonetic.append(torch.zeros(512))\n",
        "            else:\n",
        "                embed_phonetic.append(torch.from_numpy(vocab2phonvec[int(token_id)]))\n",
        "    else:\n",
        "        tokenized_sent = tokenizer.tokenize(sent)\n",
        "        for token_id, token in zip(input_ids, tokenized_sent + ['<pad>'] * (len(input_ids) - len(tokenized_sent))):\n",
        "            if token_id == tokenizer.unk_token_id:\n",
        "                embed_phonetic.append(torch.from_numpy(word2phonvec(token)))\n",
        "            elif int(token_id) in vocab2phonvec:\n",
        "                embed_phonetic.append(torch.from_numpy(vocab2phonvec[int(token_id)]))\n",
        "            else:\n",
        "                embed_phonetic.append(torch.zeros(512))\n",
        "\n",
        "    return torch.stack(embed_phonetic).float()"
      ],
      "metadata": {
        "id": "RN6G-0JXnxZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phon_dict = {'„Ñ±':['„Ñ≤','„Öã'], '„Ñ∑':['„Ñ∏','„Öå'], '„ÖÇ':['„ÖÉ','„Öç'], '„ÖÖ':['„ÖÜ'], '„Öà':['„Öâ','„Öä']}\n",
        "\n",
        "def add_noise(eumjeol):\n",
        "    result = []\n",
        "    for i,phoneme in enumerate(hgtk.letter.decompose(eumjeol)):\n",
        "        # Ï¢ÖÏÑ±ÏùÄ Î≥ÄÌïòÏßÄ ÏïäÏùå\n",
        "        if i == 2 or phoneme not in phon_dict:\n",
        "            result.append(phoneme)\n",
        "        else:\n",
        "            result.append(random.choice(phon_dict[phoneme]))\n",
        "\n",
        "    if len(result) == 2:\n",
        "        return hgtk.letter.compose(result[0], result[1])\n",
        "    else:\n",
        "        try:\n",
        "            return hgtk.letter.compose(result[0], result[1], result[2])\n",
        "        except:\n",
        "            print(eumjeol, result)\n",
        "            return eumjeol"
      ],
      "metadata": {
        "id": "NZLyowpVn_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_noise_data(sent):\n",
        "    random_eojeols = random.choices(sent.split(), k=2)\n",
        "    for random_eojeol in random_eojeols:\n",
        "        if hgtk.checker.is_hangul(random_eojeol):\n",
        "            noised_eojeol = ''.join([add_noise(eumjeol) for eumjeol in random_eojeol])\n",
        "            sent = sent.replace(random_eojeol, noised_eojeol)\n",
        "    return sent"
      ],
      "metadata": {
        "id": "hn4ySLnGoBad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ko_sents=None, en_sents=None, tokenizer=None, label_yn=True):\n",
        "        self.label_yn = label_yn\n",
        "        inputs = tokenizer(ko_sents, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        self.input_ids = []\n",
        "        self.embed_phonetic = []\n",
        "        for input_id, sent in zip(inputs['input_ids'], ko_sents):\n",
        "            input_id = input_id.clone().detach()\n",
        "            emb_pho = get_phonetic_embedding(input_id, sent)\n",
        "            self.input_ids.append(input_id)\n",
        "            self.embed_phonetic.append(emb_pho)\n",
        "            assert len(input_id) == len(emb_pho)\n",
        "        self.attention_mask = [i.clone().detach() for i in inputs['attention_mask']]\n",
        "\n",
        "        if self.label_yn:\n",
        "            labels = tokenizer(en_sents, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "            self.labels = [i.clone().detach() for i in labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label_yn:\n",
        "            return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_mask[idx], \\\n",
        "                    'embed_phonetic': self.embed_phonetic[idx], 'labels': self.labels[idx]}\n",
        "        return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_mask[idx], \\\n",
        "                    'embed_phonetic': self.embed_phonetic[idx]}"
      ],
      "metadata": {
        "id": "XrKRbx46oDTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('mt-data.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "ynohVoscez72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "3js1D_d22Ifj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['noised_ko'] = df['ÏõêÎ¨∏'].apply(lambda x: build_noise_data(x))\n",
        "df['en']=df['Î≤àÏó≠Î¨∏']\n",
        "\n",
        "msk = np.random.rand(len(df)) < 0.8\n",
        "\n",
        "train_df = df[msk]\n",
        "eval_df = df[~msk]\n",
        "\n",
        "train_df.to_csv('train.csv', index=False, encoding='utf-8')\n",
        "eval_df.to_csv('eval.csv', index=False, encoding='utf-8')\n",
        "\n",
        "train_data = CustomDataset(train_df.noised_ko.tolist(), train_df.en.tolist(), tokenizer)\n",
        "eval_data = CustomDataset(eval_df.noised_ko.tolist(), eval_df.en.tolist(), tokenizer)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# freeze original Bart Encoder, Decoder except the last layer\n",
        "# for param in model.model.encoder.layers[:-2].parameters():\n",
        "#     param.requires_grad = False\n",
        "# for param in model.model.decoder.layers[:-1].parameters():\n",
        "#    param.requires_grad = False\n",
        "\n",
        "\n",
        "# +\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    'PhoneticTranslation-noise2-epoch15-ckpt',\n",
        "    # load_best_model_at_end = True,\n",
        "    num_train_epochs=15,  # total # of training epochs\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
        "    # weight_decay=0.01,  # strength of weight decay\n",
        "    # eval_accumulation_steps=1,\n",
        "    save_steps = 999999999999999 # checkpoint Ï§ëÍ∞ÑÏóê Ï†ÄÏû•ÌïòÏßÄ ÎßêÎùºÍ≥†\n",
        ")\n",
        "# -\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,  # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,  # training arguments, defined above\n",
        "    train_dataset=train_data,  # training dataset\n",
        "    eval_dataset=eval_data,\n",
        "    # compute_metrics= compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.evaluate()\n",
        "\n",
        "model.save_pretrained('./PhoneticTranslationModel-noise2-epoch15')\n"
      ],
      "metadata": {
        "id": "qFU9St2ZkuV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inference_batch(ko_sents):\n",
        "        inputs = tokenizer(ko_sents, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        input_ids = []\n",
        "        embed_phonetic = []\n",
        "        for input_id, sent in zip(inputs['input_ids'], ko_sents):\n",
        "            input_ids.append(input_id.clone().detach())\n",
        "            embed_phonetic.append(get_phonetic_embedding(input_id, sent))\n",
        "        attention_mask = [i.clone().detach() for i in inputs['attention_mask']]\n",
        "\n",
        "        input_ids = torch.stack(input_ids)\n",
        "        attention_mask = torch.stack(attention_mask)\n",
        "        embed_phonetic = torch.stack(embed_phonetic).float()\n",
        "\n",
        "        return {'input_ids':input_ids, 'attention_mask':attention_mask, 'embed_phonetic':embed_phonetic}\n",
        "\n",
        "\n",
        "sample_texts = ['Î∞ïÎ¨ºÍ¥ÄÏù¥ Ïñ¥Îîî ÏûàÎÇòÏöî?', \"Îπ°Î¨ºÍ¥ÄÏù¥ Ïñ¥Îîî ÏûàÎÇòÏöî?\", \"Îπ°Î¨ºÏΩ¥Ïù¥ Ïñ¥Îîî ÏûàÎÇòÏöî?\", \"ÏôÑÏ©ê ÎºêÎ£®ÏóêÏöî\"]\n",
        "batch = get_inference_batch(sample_texts)\n",
        "generated_ids = model.generate(**batch)\n",
        "translated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "translated_texts\n",
        "\n",
        "for sample, result in zip(sample_texts, translated_texts):\n",
        "    print(f'{sample} --> {result}')\n"
      ],
      "metadata": {
        "id": "yGkQtOSToGxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "95LvM22Apj_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv korean-phonetic-vectors/ drive/MyDrive/"
      ],
      "metadata": {
        "id": "cNXabtD0pkm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yUCcFOtLpoUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}